{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7e2f110ee24e6283b9b30fe3d2c095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aecc2596a74b7cab46e50d1678524c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f7d59cc18743899bcc0edc7601fb32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe847c800e649ab8181dbb13c5684fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[  101,  1996,  4248,  2829,  4419, 14523,  2058,  1996, 13971,  3899,\n",
      "          1012,   102]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Token Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Tokens: ['[CLS]', 'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize with BERT tokenizer\n",
    "bert_inputs = bert_tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(\"Token IDs:\", bert_inputs['input_ids'])\n",
    "\n",
    "attention_mask = bert_inputs['attention_mask']\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "token_type_ids = bert_inputs['token_type_ids']\n",
    "print(\"Token Type IDs:\", token_type_ids)\n",
    "\n",
    "# Print the tokens themselves to understand the splits\n",
    "tokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c97002618a4a3d93b3c2ea1fcf1255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the last hidden state (embeddings): torch.Size([1, 12, 768])\n",
      "Token: [CLS], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3608,  0.2271, -0.3030, -0.1880,  0.0475])...\n",
      "Token: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3276, -0.3762, -0.5044,  0.0098,  0.9037])...\n",
      "Token: quick, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4000, -0.4212,  0.4903,  0.0033,  0.4567])...\n",
      "Token: brown, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.1209, -0.2728,  0.5550, -0.1874,  0.7759])...\n",
      "Token: fox, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.0323, -0.2305, -0.1756, -0.1121,  0.5692])...\n",
      "Token: jumps, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.2432, -0.0648,  0.3022,  0.2046,  0.7072])...\n",
      "Token: over, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.3485,  0.2208,  0.1372, -0.2754,  0.4551])...\n",
      "Token: the, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.4386, -0.4292,  0.0082,  0.0577,  0.5005])...\n",
      "Token: lazy, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.0259, 0.1114, 0.7189, 0.1787, 0.0898])...\n",
      "Token: dog, Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([0.6786, 0.0645, 0.2290, 0.3369, 0.0735])...\n",
      "Token: ., Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([-0.1088, -0.1644, -0.2962, -0.1514,  0.1527])...\n",
      "Token: [SEP], Embedding Dimension: torch.Size([768]), Embedding (first 5 components): tensor([ 0.7099,  0.4367, -0.4851,  0.1776,  0.1749])...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Obtain the embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden state (embeddings)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Print the dimensions of the embeddings\n",
    "print(\"Shape of the last hidden state (embeddings):\", last_hidden_states.shape)\n",
    "\n",
    "# Print embeddings for each token along with their vector dimension\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "for token, embedding in zip(tokens, last_hidden_states[0]):\n",
    "    print(f\"Token: {token}, Embedding Dimension: {embedding.shape}, Embedding (first 5 components): {embedding[:5]}...\")  # Display first 5 components for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_sentence_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy()\n",
    "    return sentence_embedding\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A fast brown fox leaps over a sleepy dog.\",\n",
    "    \"This sentence is completely different from the others.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for texts\n",
    "embeddings = [get_sentence_embedding(text) for text in texts]\n",
    "print(embeddings)\n",
    "\n",
    "\n",
    "# Query text\n",
    "query_text = \"The quick red fox jumps over the lazy dog.\"\n",
    "query_embedding = get_sentence_embedding(query_text)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = cosine_similarity(query_embedding, np.vstack(embeddings))\n",
    "\n",
    "# Print query text\n",
    "print (f\"Query text: {query_text}\")\n",
    "\n",
    "# Print similarities\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Similarity with '{text}': {similarities[0][i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
